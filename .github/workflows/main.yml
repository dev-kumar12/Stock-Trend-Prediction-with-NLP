name: Run-Notebook-Daily

on:
  schedule:
    # 1. MORNING CHECK: Runs at 1:00 AM UTC (6:30 AM IST). This catches
    #    any EOD data that was delayed overnight.
    - cron: '0 1 * * *' 
    # 2. EVENING FINAL: Runs at 2:00 PM UTC (7:30 PM IST). This captures
    #    the final, verified closing data immediately after the market closes.
    - cron: '0 14 * * *'
  # This still allows manual running when needed
  workflow_dispatch:

jobs:
  build-and-run:
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Check out the LATEST version of your code
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          # This forces it to get the newest commit
          ref: 'master'

     # Step 2: Set up Python
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      # Step 3: Install dependencies (with debugging)
      - name: Install dependencies
        run: |
          echo "--- Starting optimized installation ---"
          # Install all dependencies without saving the downloaded files to save disk space
          pip install -r requirements.txt --no-cache-dir
          echo "--- Installation complete. Proceeding to run notebook. ---"
      # Step 4: Run the notebook
      - name: Run Data_Collection.ipynb
        run: |
          jupyter nbconvert --to notebook --execute Data_Collection.ipynb --output Data_Collection.ipynb --inplace

      # Step 5: Commit the new data
      - name: Commit and push new data
        run: |
          git config --global user.name 'github-actions'
          git config --global user.email 'github-actions@github.com'
          git add final_master_dataset.csv lstm_model.h5 scaler.pkl
          git commit -m "Automated daily data update" -a || echo "No changes to commit"
          git push
